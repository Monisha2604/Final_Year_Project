{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN_spark.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Monisha2604/Final_Year_Project/blob/master/ANN_spark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAUTTzYknD1Z",
        "outputId": "998982bb-3a1e-4a64-b065-952f01e55265"
      },
      "source": [
        "pip install keras"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.4.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras) (1.19.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras) (3.1.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->keras) (1.5.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHENbFQVnAg0"
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://www-us.apache.org/dist/spark/spark-3.0.3/spark-3.0.3-bin-hadoop2.7.tgz\n",
        "!tar xf spark-3.0.3-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96L3w6sjztPK"
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.3-bin-hadoop2.7\"\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "# spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8djw5I_xnGqO",
        "outputId": "c0bfb512-54b3-4360-9c8d-0c0bbdd2de49"
      },
      "source": [
        "pip install elephas"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting elephas\n",
            "  Downloading https://files.pythonhosted.org/packages/a4/8c/a459d974e01f782e2709c74c280030c0424115f022f33a887ced9e03282b/elephas-2.1.0.tar.gz\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from elephas) (0.29.23)\n",
            "Requirement already satisfied: tensorflow!=2.2.*,>=2 in /usr/local/lib/python3.7/dist-packages (from elephas) (2.5.0)\n",
            "Collecting keras==2.2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/ba/2d058dcf1b85b9c212cc58264c98a4a7dd92c989b798823cc5690d062bb2/Keras-2.2.5-py2.py3-none-any.whl (336kB)\n",
            "\u001b[K     |████████████████████████████████| 337kB 14.1MB/s \n",
            "\u001b[?25hCollecting hyperas\n",
            "  Downloading https://files.pythonhosted.org/packages/04/34/87ad6ffb42df9c1fa9c4c906f65813d42ad70d68c66af4ffff048c228cd4/hyperas-0.4.1-py3-none-any.whl\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.7/dist-packages (from elephas) (1.1.4)\n",
            "Collecting h5py==2.10.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/c0/abde58b837e066bca19a3f7332d9d0493521d7dd6b48248451a9e3fe2214/h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 43.7MB/s \n",
            "\u001b[?25hCollecting pyspark<3.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/89/db/e18cfd78e408de957821ec5ca56de1250645b05f8523d169803d8df35a64/pyspark-3.1.2.tar.gz (212.4MB)\n",
            "\u001b[K     |████████████████████████████████| 212.4MB 63kB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.2.*,>=2->elephas) (0.36.2)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.2.*,>=2->elephas) (1.15.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.2.*,>=2->elephas) (3.3.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.2.*,>=2->elephas) (1.19.5)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.2.*,>=2->elephas) (0.12.0)\n",
            "Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.2.*,>=2->elephas) (1.34.1)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.2.*,>=2->elephas) (1.12.1)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.2.*,>=2->elephas) (2.5.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.2.*,>=2->elephas) (1.12)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.2.*,>=2->elephas) (1.1.2)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.2.*,>=2->elephas) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.2.*,>=2->elephas) (2.5.0)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.2.*,>=2->elephas) (0.4.0)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.2.*,>=2->elephas) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.2.*,>=2->elephas) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.2.*,>=2->elephas) (3.7.4.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.2.*,>=2->elephas) (3.17.3)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.2.*,>=2->elephas) (1.6.3)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5->elephas) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5->elephas) (3.13)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from hyperas->elephas) (5.6.1)\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.7/dist-packages (from hyperas->elephas) (0.1.2)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from hyperas->elephas) (0.3)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from hyperas->elephas) (5.1.3)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.7/dist-packages (from hyperas->elephas) (1.0.0)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask->elephas) (7.1.2)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask->elephas) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from flask->elephas) (1.0.1)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask->elephas) (2.11.3)\n",
            "Collecting py4j==0.10.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 47.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow!=2.2.*,>=2->elephas) (57.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow!=2.2.*,>=2->elephas) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow!=2.2.*,>=2->elephas) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow!=2.2.*,>=2->elephas) (1.8.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow!=2.2.*,>=2->elephas) (0.6.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow!=2.2.*,>=2->elephas) (1.32.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow!=2.2.*,>=2->elephas) (0.4.4)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->hyperas->elephas) (0.5.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbconvert->hyperas->elephas) (4.7.1)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->hyperas->elephas) (0.7.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->hyperas->elephas) (3.3.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->hyperas->elephas) (1.4.3)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->hyperas->elephas) (0.8.4)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from nbconvert->hyperas->elephas) (2.6.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->hyperas->elephas) (5.0.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from hyperopt->hyperas->elephas) (0.16.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.7/dist-packages (from hyperopt->hyperas->elephas) (3.11.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from hyperopt->hyperas->elephas) (4.41.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from hyperopt->hyperas->elephas) (2.5.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat->hyperas->elephas) (2.6.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from nbformat->hyperas->elephas) (0.2.0)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter->hyperas->elephas) (5.1.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jupyter->hyperas->elephas) (7.6.3)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from jupyter->hyperas->elephas) (4.10.1)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter->hyperas->elephas) (5.2.0)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter->hyperas->elephas) (5.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->flask->elephas) (2.0.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow!=2.2.*,>=2->elephas) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow!=2.2.*,>=2->elephas) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow!=2.2.*,>=2->elephas) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow!=2.2.*,>=2->elephas) (1.24.3)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow!=2.2.*,>=2->elephas) (4.6.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow!=2.2.*,>=2->elephas) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow!=2.2.*,>=2->elephas) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow!=2.2.*,>=2->elephas) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow!=2.2.*,>=2->elephas) (1.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->hyperas->elephas) (20.9)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->hyperas->elephas) (0.5.1)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx->hyperopt->hyperas->elephas) (4.4.2)\n",
            "Requirement already satisfied: jupyter-client>=4.1 in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->hyperas->elephas) (5.3.5)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->hyperas->elephas) (1.9.0)\n",
            "Requirement already satisfied: pyzmq>=17.1 in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->hyperas->elephas) (22.1.0)\n",
            "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->hyperas->elephas) (5.5.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->hyperas->elephas) (3.5.1)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->hyperas->elephas) (1.0.0)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->hyperas->elephas) (5.1.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-console->jupyter->hyperas->elephas) (1.0.18)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->hyperas->elephas) (0.10.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->hyperas->elephas) (1.7.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.5->tensorflow!=2.2.*,>=2->elephas) (3.4.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow!=2.2.*,>=2->elephas) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow!=2.2.*,>=2->elephas) (3.1.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->bleach->nbconvert->hyperas->elephas) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=4.1->qtconsole->jupyter->hyperas->elephas) (2.8.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->hyperas->elephas) (0.8.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->hyperas->elephas) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->hyperas->elephas) (0.7.5)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.0->jupyter-console->jupyter->hyperas->elephas) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter->hyperas->elephas) (0.7.0)\n",
            "Building wheels for collected packages: elephas, pyspark\n",
            "  Building wheel for elephas (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for elephas: filename=elephas-2.1.0-cp37-none-any.whl size=27611 sha256=851198d2dc834807f15d82d7313fc06fe49f549aabe40b84206264dbe1291f9a\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/8e/f7/afeaa15a424e0df01ff445dea2ac4cfddda282329494bbb027\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.2-py2.py3-none-any.whl size=212880768 sha256=d9a9acd0e28582d71e48cd32cacca1b21f9721112c7ad07a5acab454c60213ec\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/1b/2c/30f43be2627857ab80062bef1527c0128f7b4070b6b2d02139\n",
            "Successfully built elephas pyspark\n",
            "\u001b[31mERROR: tensorflow 2.5.0 has requirement h5py~=3.1.0, but you'll have h5py 2.10.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: h5py, keras-applications, keras, hyperas, py4j, pyspark, elephas\n",
            "  Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Found existing installation: Keras 2.4.3\n",
            "    Uninstalling Keras-2.4.3:\n",
            "      Successfully uninstalled Keras-2.4.3\n",
            "Successfully installed elephas-2.1.0 h5py-2.10.0 hyperas-0.4.1 keras-2.2.5 keras-applications-1.0.8 py4j-0.10.9 pyspark-3.1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "py4j",
                  "pyspark"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTg7EQoYnMq9"
      },
      "source": [
        "from elephas.ml_model import ElephasEstimator\n",
        "from elephas.ml.adapter import to_data_frame\n",
        " \n",
        " \n",
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.mllib.evaluation import RegressionMetrics\n",
        "from pyspark.ml import Pipeline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cn3JD2pYlt-E"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2KJeeIwnSWZ"
      },
      "source": [
        "from pyspark.sql import SQLContext\n",
        "from pyspark.ml.linalg import Vectors\n",
        "import numpy as np\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWjHl_2g_Dgv",
        "outputId": "52747acf-f7e2-4798-82f1-ced57a45f5ac"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1a8Gi2Gl47J"
      },
      "source": [
        "df=pd.read_csv(\"/content/drive/MyDrive/MyTable_13_snigdha.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FsXm8xfmDwd",
        "outputId": "fc37b4be-c4f3-40d6-ac46-6723994b55ef"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['objid', 'ra', 'dec', 'psfMag_u', 'psfMag_g', 'psfMag_r', 'psfMag_i',\n",
              "       'psfMag_z', 'dered_u', 'dered_g', 'dered_r', 'dered_i', 'dered_z',\n",
              "       'fiberMag_u', 'fiberMag_g', 'fiberMag_r', 'fiberMag_i', 'fiberMag_z',\n",
              "       'petroR50_r', 'petroR50_z', 'petroR90_r', 'petroR90_z', 'r', 'i', 'z',\n",
              "       'redshift'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-Ld9xAymE68"
      },
      "source": [
        "df=df.drop(['objid', 'ra', 'dec'],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTHHiMegmTci",
        "outputId": "ea758b04-bb61-4ceb-80e0-161c0b42013f"
      },
      "source": [
        "col=df.columns\n",
        "len(col)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "md2J1G9EmVIH"
      },
      "source": [
        "df[df[\"dered_u\"]==-9999.0]=np.nan\n",
        "df[df[\"dered_g\"]==-9999.0]=np.nan\n",
        "df[df[\"dered_r\"]==-9999.0]=np.nan\n",
        "df[df[\"dered_i\"]==-9999.0]=np.nan\n",
        "df[df[\"dered_z\"]==-9999.0]=np.nan\n",
        "\n",
        "df[df[\"fiberMag_u\"]==-9999]=np.nan\n",
        "df[df[\"fiberMag_g\"]==-9999]=np.nan\n",
        "df[df[\"fiberMag_r\"]==-9999]=np.nan\n",
        "df[df[\"fiberMag_i\"]==-9999]=np.nan\n",
        "df[df[\"fiberMag_z\"]==-9999]=np.nan\n",
        "\n",
        "df[df[\"r\"]==-9999]=np.nan\n",
        "df[df[\"i\"]==-9999]=np.nan\n",
        "df[df[\"z\"]==-9999]=np.nan\n",
        "df[df[\"petroR50_r\"]==-9999]=np.nan\n",
        "df[df[\"petroR90_r\"]==-9999]=np.nan\n",
        "\n",
        "df[df[\"psfMag_g\"]==-9999.0]=np.nan\n",
        "df[df[\"psfMag_r\"]==-9999.0]=np.nan\n",
        "df[df[\"psfMag_i\"]==-9999.0]=np.nan\n",
        "df[df[\"psfMag_z\"]==-9999.0]=np.nan"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcbrUFi3mZ5R"
      },
      "source": [
        "df=df.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQ-idm9pmclr",
        "outputId": "325f7c20-e417-4c54-921a-9de3ada520b4"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "psfMag_u      0\n",
              "psfMag_g      0\n",
              "psfMag_r      0\n",
              "psfMag_i      0\n",
              "psfMag_z      0\n",
              "dered_u       0\n",
              "dered_g       0\n",
              "dered_r       0\n",
              "dered_i       0\n",
              "dered_z       0\n",
              "fiberMag_u    0\n",
              "fiberMag_g    0\n",
              "fiberMag_r    0\n",
              "fiberMag_i    0\n",
              "fiberMag_z    0\n",
              "petroR50_r    0\n",
              "petroR50_z    0\n",
              "petroR90_r    0\n",
              "petroR90_z    0\n",
              "r             0\n",
              "i             0\n",
              "z             0\n",
              "redshift      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xk-qCUwTmfON"
      },
      "source": [
        "df.to_csv(\"redshift.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54N_9LWLmkuI"
      },
      "source": [
        "conf=SparkConf().setAppName('MLP').setMaster('local[*]')\n",
        "sc=SparkContext(conf=conf)\n",
        "sql_context=SQLContext(sc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhHIPfLdnXDv"
      },
      "source": [
        "data=sql_context.read.csv(\"/content/redshift.csv\",header=True,inferSchema=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCv0dNRVne-J"
      },
      "source": [
        "data=data.sample(False,0.4,1234)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TnqWyvQnlto",
        "outputId": "7cbcdc8d-5b60-4e2f-cc0b-9c5c510ed53b"
      },
      "source": [
        "data.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "996495"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLSp1834noBj"
      },
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "assembler=VectorAssembler(\n",
        "    inputCols=['psfMag_u',\n",
        "               'psfMag_g',\n",
        "               'psfMag_r',\n",
        "               'psfMag_i',\n",
        "               'psfMag_z',\n",
        "               'dered_u', \n",
        "              'dered_g', \n",
        "               'dered_r', \n",
        "               'dered_i', \n",
        "               'dered_z', \n",
        "               'fiberMag_u', \n",
        "               'fiberMag_g', \n",
        "               'fiberMag_r', \n",
        "              'fiberMag_i', \n",
        "               'fiberMag_z', \n",
        "               'petroR50_r',\n",
        "               'petroR50_z',\n",
        "                'petroR90_r',\n",
        "                'petroR90_z',\n",
        "               'r', \n",
        "               'i', \n",
        "               'z'],\n",
        "    outputCol=\"features\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcVuArn_o-12"
      },
      "source": [
        "data=assembler.transform(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUn_QPR7phxy"
      },
      "source": [
        "output=data.select(\"features\",\"redshift\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fr7kh1evpj-2"
      },
      "source": [
        "(train_df,test_df)=output.randomSplit([0.8,0.2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ag4VsdtpmEv"
      },
      "source": [
        "from pyspark.ml.feature import StandardScaler\n",
        "\n",
        "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\", withStd=True, withMean=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBF4dCz-pok5"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation,Dense,Dropout,BatchNormalization\n",
        "from tensorflow.keras import regularizers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eh49IdGEprvE"
      },
      "source": [
        "from tensorflow.keras import optimizers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brHOTodppvJE"
      },
      "source": [
        "input_dim = len(train_df.select(\"features\").first()[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpwEHwZmpx4i"
      },
      "source": [
        "model = Sequential()\n",
        " \n",
        "'''\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=25, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))'''\n",
        " \n",
        "model.add(Dense(256, input_shape=(input_dim,))) # shape[1] will be number of columns\n",
        "#model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "#kernel_regularizer=regularizers.l2(0.001)\n",
        "\n",
        "model.add(Dense(256))\n",
        "#model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        " \n",
        "model.add(Dense(256))\n",
        "#model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        " \n",
        "model.add(Dense(1))\n",
        "model.add(Activation('linear'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34AJiYwHqQ6E"
      },
      "source": [
        "opt = optimizers.Adam(learning_rate=0.0001)\n",
        "sgd_conf = optimizers.serialize(opt)\n",
        "# no Adamax\n",
        "#no Adam\n",
        "#Adadelta\n",
        "#no RMSprop\n",
        "  #opt = optimizers.RMSprop(lr=0.01)\n",
        "  #sgd_conf = optimizers.serialize(opt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWFTaNNzqUrZ",
        "outputId": "565072da-eb70-4a0f-8ab2-df53d530d88d"
      },
      "source": [
        "estimator = ElephasEstimator()\n",
        "estimator.set_keras_model_config(model.to_yaml())\n",
        "estimator.set_optimizer_config(sgd_conf)\n",
        "estimator.set_mode(\"synchronous\")\n",
        "estimator.set_loss(\"mse\")\n",
        "estimator.set_metrics(['mse'])\n",
        "estimator.set_epochs(10)\n",
        "estimator.set_batch_size(500)\n",
        "estimator.set_validation_split(0.10)\n",
        "estimator.set_categorical_labels(False)\n",
        "estimator.set_loss(\"mse\")\n",
        "estimator.set_metrics([\"acc\"])\n",
        "\n",
        "estimator.setFeaturesCol(\"features\")\n",
        "estimator.setLabelCol(\"label\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ElephasEstimator_8d7bddc18275"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCugLhSItV-p",
        "outputId": "bc8e5460-43ca-4bce-a79e-3d4449893369"
      },
      "source": [
        "\n",
        "estimator = ElephasEstimator()\n",
        "estimator.set_keras_model_config(model.to_yaml())\n",
        "estimator.set_optimizer_config(sgd_conf)\n",
        "estimator.setFeaturesCol(\"features\")\n",
        "estimator.setLabelCol(\"label\")\n",
        "estimator.set_mode(\"synchronous\")\n",
        "estimator.set_loss(\"mae\")\n",
        "estimator.set_metrics(['mae'])\n",
        "estimator.set_epochs(100)\n",
        "estimator.set_batch_size(256)\n",
        "estimator.set_validation_split(0.01)\n",
        "estimator.set_categorical_labels(False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ElephasEstimator_f066e0a23840"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Na5HzGhqXD0"
      },
      "source": [
        "from pyspark.ml import Pipeline\n",
        " \n",
        "pipeline = Pipeline(stages=[estimator])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKKuw8_0qjl0"
      },
      "source": [
        "train_df=train_df.withColumnRenamed(\"redshift\",\"label\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgiCxfqAqtTi",
        "outputId": "48e93022-2c1d-4537-d2d6-4d17bc22b569"
      },
      "source": [
        "from pyspark.mllib.evaluation import MulticlassMetrics\n",
        "import timeit \n",
        "start = timeit.default_timer()\n",
        "fitted_pipeline = pipeline.fit(train_df) # Fit model to data\n",
        "stop = timeit.default_timer()\n",
        "execution_time = (stop - start)/60\n",
        "print(\"Program Executed in minutes \"+str(execution_time))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">>> Fit model\n",
            ">>> Synchronous training complete.\n",
            "Program Executed in minutes 36.71486127196665\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5y9iux3q4Wm",
        "outputId": "66011970-6ccf-4253-c67c-45b1d90f2de5"
      },
      "source": [
        "test_df.show(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+----------+\n",
            "|            features|     label|\n",
            "+--------------------+----------+\n",
            "|[15.2698299999999...|       0.0|\n",
            "|[15.72344,15.3647...|0.04702275|\n",
            "+--------------------+----------+\n",
            "only showing top 2 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebLCtOpZyphN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqIyfqJkzQid"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGGx2m4Nq7Cw"
      },
      "source": [
        "prediction = fitted_pipeline.transform(test_df) # <-- The same code evaluates test data."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKDZebjvLS37"
      },
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQ8QxKL_rBBx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5775c78c-f889-400e-ac7a-52fb6eb934c5"
      },
      "source": [
        "evaluator = RegressionEvaluator(labelCol=\"redshift\", predictionCol=\"prediction\", metricName=\"r2\")\n",
        "rmse = evaluator.evaluate(prediction)\n",
        "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Root Mean Squared Error (RMSE) on test data = -0.627669\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKmkVqoE8pUt"
      },
      "source": [
        "from pyspark.mllib.tree import GradientBoostedTrees, GradientBoostedTreesModel"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}